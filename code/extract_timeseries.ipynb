{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Details:\n",
    "# Study: Brain Network Organization and Behavior\n",
    "# Note: This notebook extracts the adjacency matrix all subjects using the Seitzman et al. (2020) atlas\n",
    "# Note: All paths are relative to the current working directory\n",
    "# Note: Subjects should be organized into directories that encode the given experimental condition\n",
    "\n",
    "# Credits:\n",
    "# Written by Richard Huskey\n",
    "# https://nilearn.github.io/auto_examples/03_connectivity/plot_group_level_connectivity.html#sphx-glr-auto-examples-03-connectivity-plot-group-level-connectivity-py\n",
    "\n",
    "\n",
    "# Notes and dependencies\n",
    "# None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "from nilearn import datasets\n",
    "import os\n",
    "os.system('mkdir -p time_series_01608') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make meta-data to distinguish flow,bore,and frus\n",
    "import pandas\n",
    "colnames = ['sub', 'condition', 'file']\n",
    "metadata_scan_full = pandas.read_csv('/data/meta_full.csv', names=colnames)\n",
    "sub_full = metadata_scan_full['sub'].drop([0],axis=0).tolist()\n",
    "condition_full = metadata_scan_full['condition'].drop([0],axis=0).tolist()\n",
    "file_full = metadata_scan_full['file'].drop([0],axis=0).tolist()\n",
    "file_full = [s.replace('.nii.gz', '') for s in file_full]\n",
    "print(file_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_full = []\n",
    "for i in file_full:\n",
    "    filenames_full.append('/data/merger_01608_Seitzman/{}.nii.gz'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the coordinate of the Seitzman et al. (2020) atlas\n",
    "new_atlas = pandas.read_table(\"/data/analysis/ROIs_300inVol_MNI_allInfo.txt\", \n",
    "                              delim_whitespace=True)\n",
    "\n",
    "index_5mm = new_atlas['radius(mm)'] == 5\n",
    "index_4mm = new_atlas['radius(mm)'] == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a table with the x,y,z coordinates of each seed ROI\n",
    "\n",
    "coords = np.vstack((new_atlas['x'], new_atlas['y'], new_atlas['z'])).T\n",
    "coords_5mm = coords[index_5mm,:]\n",
    "coords_4mm = coords[index_4mm,:]\n",
    "print('Stacked power coordinates in array of shape {0}.'.format(coords_4mm.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, lets make some masks\n",
    "# Note, these are 5mm spheres for cortical regions and 4mm spheres for subcortical regions\n",
    "\n",
    "masker_5mm = input_data.NiftiSpheresMasker(\n",
    "    seeds=coords_5mm, smoothing_fwhm=None, radius=5.,\n",
    "    detrend=True, t_r=2.0, memory='nilearn_cache', memory_level=1)\n",
    "masker_4mm = input_data.NiftiSpheresMasker(\n",
    "    seeds=coords_4mm, smoothing_fwhm=None, radius=4,\n",
    "    detrend=True, t_r=2.0, allow_overlap = True, memory='nilearn_cache', memory_level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We transform the fMRI images to time series for each node by averaging voxels in the defined sphere nodes\n",
    "# Then we append the time series to the list\n",
    "pooled_subjects = []\n",
    "\n",
    "for f in filenames_full:\n",
    "    print(\"extracting {} \".format(f))\n",
    "    time_series_5mm = masker_5mm.fit_transform(f)\n",
    "    time_series_4mm = masker_4mm.fit_transform(f)\n",
    "    time_series = np.hstack((time_series_5mm,time_series_4mm))\n",
    "    \n",
    "    pooled_subjects.append(time_series)\n",
    "    print(\"just finished {} \".format(f))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pooled_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that each time series is a 120 (TR) * 300 (nodes) matrix\n",
    "for i in range(len(pooled_subjects)):\n",
    "    assert pooled_subjects[i].shape[0] == 120\n",
    "    assert pooled_subjects[i].shape[1] == 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the time series data as txt files\n",
    "out_file_names=[s.replace('_bold_space-MNI152NLin2009aAsym_preproc_merged', '') for s in file_full]\n",
    "out_file_names=[s.replace('_task-game', '') for s in out_file_names]\n",
    "\n",
    "for i in range(len(pooled_subjects)):\n",
    "    np.savetxt('time_series_01608/{}.out'.format(out_file_names[i]), pooled_subjects[i], delimiter=',')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
