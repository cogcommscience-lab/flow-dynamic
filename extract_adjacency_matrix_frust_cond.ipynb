{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Details:\n",
    "# Study: Brain Network Organization and Behavior\n",
    "# Note: This notebook processes the frustration condition for all subjects usint the Power 264 atlas\n",
    "\n",
    "\n",
    "# Credits:\n",
    "# Written by Richard Huskey\n",
    "# https://nilearn.github.io/auto_examples/03_connectivity/plot_group_level_connectivity.html#sphx-glr-auto-examples-03-connectivity-plot-group-level-connectivity-py\n",
    "\n",
    "\n",
    "# Notes and dependencies\n",
    "# None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huskeyadmin/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "from nilearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nii/sub-005_task-game_run-03_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\n",
      "nii/sub-006_task-game_run-01_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\n",
      "nii/sub-007_task-game_run-03_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\n",
      "nii/sub-008_task-game_run-02_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\n",
      "nii/sub-009_task-game_run-02_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\n",
      "nii/sub-011_task-game_run-01_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\n",
      "nii/sub-012_task-game_run-02_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\n",
      "nii/sub-014_task-game_run-01_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\n",
      "nii/sub-015_task-game_run-01_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\n",
      "nii/sub-016_task-game_run-02_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\n",
      "nii/sub-017_task-game_run-02_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\n",
      "nii/sub-020_task-game_run-03_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\n",
      "nii/sub-021_task-game_run-02_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\n",
      "nii/sub-023_task-game_run-01_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\n",
      "nii/sub-024_task-game_run-01_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\n",
      "nii/sub-025_task-game_run-03_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\n",
      "nii/sub-026_task-game_run-03_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\n",
      "nii/sub-028_task-game_run-02_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\n",
      "nii/sub-029_task-game_run-01_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\n",
      "nii/sub-030_task-game_run-03_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\n",
      "nii/sub-031_task-game_run-01_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\n",
      "nii/sub-032_task-game_run-01_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\n",
      "nii/sub-033_task-game_run-01_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\n",
      "nii/sub-034_task-game_run-02_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\n",
      "nii/sub-036_task-game_run-02_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\n",
      "nii/sub-037_task-game_run-03_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\n",
      "nii/sub-039_task-game_run-02_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\n",
      "nii/sub-040_task-game_run-01_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\n",
      "nii/sub-041_task-game_run-02_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\n",
      "nii/sub-042_task-game_run-03_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\n"
     ]
    }
   ],
   "source": [
    "# Import one subject per line\n",
    "# NOTE: sub count starts at 005 (subs 001-004 were pilot scans using a different procedure)\n",
    "# NOTE: sub 010 excluded due to abnormal radiological reading\n",
    "# NOTE: subs 027 and 038 exhibited contraindication to scanning and therefore are excluded\n",
    "# NOTE: subs 022 and 035 were excluded since they failed the behavioral compliance check\n",
    "# NOTE: subs 013, 018, and 019 were excluded since they were outliers in a group-level MRIQC analysis\n",
    "\n",
    "filenames = sorted(glob.glob('nii/*.gz'))\n",
    "\n",
    "for f in filenames:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Power atlas comes with dict_keys(['rois', 'description']).\n"
     ]
    }
   ],
   "source": [
    "# This imports the Power 2011 atlas with 264 cortical and subcortical ROIs\n",
    "\n",
    "power = datasets.fetch_coords_power_2011()\n",
    "print('Power atlas comes with {0}.'.format(power.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked power coordinates in array of shape (264, 3).\n"
     ]
    }
   ],
   "source": [
    "# Makes a table with the x,y,z coordinates of each seed ROI\n",
    "\n",
    "coords = np.vstack((power.rois['x'], power.rois['y'], power.rois['z'])).T\n",
    "\n",
    "print('Stacked power coordinates in array of shape {0}.'.format(coords.shape))\n",
    "\n",
    "# The code below exports the ROI x,y,z coordinates of each seed ROI to a text file\n",
    "\n",
    "np.savetxt('adjacency_matrix/power_rois.txt',coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, lets make some masks\n",
    "# Note, these are 5mm spheres so that ROIs do not overlap\n",
    "# They also highpass filter the data since this wasn't done in fmriprep (filter = 250s)\n",
    "\n",
    "masker = input_data.NiftiSpheresMasker(\n",
    "    seeds=coords, smoothing_fwhm=None, radius=5.,\n",
    "    detrend=True, high_pass=.004, t_r=2.0, memory='nilearn_cache', memory_level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a timeseries matrix for each subect for each run\n",
    "\n",
    "pooled_subjects = []\n",
    "\n",
    "for f in filenames:\n",
    "    time_series = masker.fit_transform(f)\n",
    "    pooled_subjects.append(time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If files are being imported correctly, there should 120 volumes reported here\n",
    "\n",
    "print ('timeseries has {0} samples. This is how many volumes there are in the functional run'.format(time_series.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, lets estimate some connectivities using correlation\n",
    "\n",
    "from nilearn.connectome import ConnectivityMeasure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_measure = ConnectivityMeasure(kind='correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute individual correlation matricies for each subject\n",
    "\n",
    "correlation_matrices = correlation_measure.fit_transform(pooled_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape should be (n, 264, 264) where n = the number of subjects/runs in your study\n",
    "\n",
    "print('Correlations of subject runs are stacked in an array of shape {0}'\n",
    "      .format(correlation_matrices.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates a mean (group-level) correlation matrix\n",
    "# This tells you the shape of your mean correlation matrix\n",
    "# Shape should just be (264, 264) because you are taking the average correlation of all subjects here\n",
    "\n",
    "mean_correlation_matrix = correlation_measure.mean_\n",
    "print('Mean correlation has shape {0}.'.format(mean_correlation_matrix.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the diagonal to zero (This facilitates the Fishers Z Transform in the next step)\n",
    "\n",
    "np.fill_diagonal(mean_correlation_matrix, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fishers Z Transform the average (group-level) matrix\n",
    "\n",
    "fisherz_mean_correlation_matrix = np.arctanh(mean_correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This saves the Fisher Z transformed correlation matrix as a txt output in the current working directory\n",
    "\n",
    "np.savetxt('adjacency_matrix/frust_cond_corel_matrix.txt',fisherz_mean_correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, lets estimate some connectivities using covariance\n",
    "\n",
    "covariance_measure = ConnectivityMeasure(kind='covariance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariance_matricies = covariance_measure.fit_transform(pooled_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape should be (n, 264, 264) where n = the number of subjects/runs in your study\n",
    "\n",
    "print('Covariances of subject runs are stacked in an array of shape {0}'\n",
    "      .format(covariance_matricies.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tells you the shape of your mean covariance matrix\n",
    "# Shape should just be (264, 264) because you are taking the average correlation of all subjects here\n",
    "\n",
    "mean_covariance_matrix = covariance_measure.mean_\n",
    "print('Mean covariance has shape {0}.'.format(mean_covariance_matrix.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This saves the covariance matrix as a txt output in the current working directory\n",
    "\n",
    "np.savetxt('adjacency_matrix/frust_cond_covar_matrix.txt',mean_covariance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the diagonal to zero for each subject's individual correlation matrix\n",
    "\n",
    "for j in range(len(correlation_matrices)):\n",
    "    np.fill_diagonal(correlation_matrices[j], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fishers Z transforms each subject's correlation matrix\n",
    "\n",
    "fisherz_correlation_matrices = np.arctanh(correlation_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This saves the correlation matrix for each subject as a txt output in the current working directory\n",
    "\n",
    "for i in range(len(fisherz_correlation_matrices)):\n",
    "    np.savetxt('adjacency_matrix/frust_cond_corel_matrix_%i.txt'%i, fisherz_correlation_matrices[i] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
