{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Details:\n",
    "# Study: Brain Network Organization and Behavior\n",
    "# Note: This notebook processes the flow condition for all subjects usint the Power 264 atlas\n",
    "\n",
    "\n",
    "# Credits:\n",
    "# Written by Richard Huskey\n",
    "# https://nilearn.github.io/auto_examples/03_connectivity/plot_group_level_connectivity.html#sphx-glr-auto-examples-03-connectivity-plot-group-level-connectivity-py\n",
    "\n",
    "\n",
    "# Notes and dependencies\n",
    "# None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import one subject per line\n",
    "# NOTE: sub count starts at 005 (subs 001-004 were pilot scans using a different procedure)\n",
    "# NOTE: sub 010 excluded due to abnormal radiological reading\n",
    "# NOTE: subs 027 and 038 exhibited contraindication to scanning and therefore are excluded\n",
    "# NOTE: subs 022 and 035 were excluded since they failed the behavioral compliance check\n",
    "# NOTE: subs 013, 018, and 019 were excluded since they were outliers in a group-level MRIQC analysis\n",
    "\n",
    "\n",
    "from nilearn import image\n",
    "from nilearn.image import load_img\n",
    "\n",
    "sub005 = image.load_img(\"/home/huskeyadmin/Desktop/merged/sub-005_task-game_run-01_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\")\n",
    "sub006 = image.load_img(\"/home/huskeyadmin/Desktop/merged/sub-006_task-game_run-03_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\")\n",
    "sub007 = image.load_img(\"/home/huskeyadmin/Desktop/merged/sub-007_task-game_run-02_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\")\n",
    "sub008 = image.load_img(\"/home/huskeyadmin/Desktop/merged/sub-008_task-game_run-01_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\")\n",
    "sub009 = image.load_img(\"/home/huskeyadmin/Desktop/merged/sub-009_task-game_run-03_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\")\n",
    "sub011 = image.load_img(\"/home/huskeyadmin/Desktop/merged/sub-011_task-game_run-02_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\")\n",
    "sub012 = image.load_img(\"/home/huskeyadmin/Desktop/merged/sub-012_task-game_run-01_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\")\n",
    "sub014 = image.load_img(\"/home/huskeyadmin/Desktop/merged/sub-014_task-game_run-03_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\")\n",
    "sub015 = image.load_img(\"/home/huskeyadmin/Desktop/merged/sub-015_task-game_run-03_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\")\n",
    "sub016 = image.load_img(\"/home/huskeyadmin/Desktop/merged/sub-016_task-game_run-01_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\")\n",
    "sub017 = image.load_img(\"/home/huskeyadmin/Desktop/merged/sub-017_task-game_run-01_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\")\n",
    "sub020 = image.load_img(\"/home/huskeyadmin/Desktop/merged/sub-020_task-game_run-02_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\")\n",
    "sub021 = image.load_img(\"/home/huskeyadmin/Desktop/merged/sub-021_task-game_run-01_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\")\n",
    "sub023 = image.load_img(\"/home/huskeyadmin/Desktop/merged/sub-023_task-game_run-02_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\")\n",
    "sub024 = image.load_img(\"/home/huskeyadmin/Desktop/merged/sub-024_task-game_run-03_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\")\n",
    "sub025 = image.load_img(\"/home/huskeyadmin/Desktop/merged/sub-025_task-game_run-02_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\")\n",
    "sub026 = image.load_img(\"/home/huskeyadmin/Desktop/merged/sub-026_task-game_run-01_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\")\n",
    "sub028 = image.load_img(\"/home/huskeyadmin/Desktop/merged/sub-028_task-game_run-01_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\")\n",
    "sub029 = image.load_img(\"/home/huskeyadmin/Desktop/merged/sub-029_task-game_run-02_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\")\n",
    "sub030 = image.load_img(\"/home/huskeyadmin/Desktop/merged/sub-030_task-game_run-01_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\")\n",
    "sub031 = image.load_img(\"/home/huskeyadmin/Desktop/merged/sub-031_task-game_run-03_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\")\n",
    "sub032 = image.load_img(\"/home/huskeyadmin/Desktop/merged/sub-032_task-game_run-02_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\")\n",
    "sub033 = image.load_img(\"/home/huskeyadmin/Desktop/merged/sub-033_task-game_run-03_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\")\n",
    "sub034 = image.load_img(\"/home/huskeyadmin/Desktop/merged/sub-034_task-game_run-03_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\")\n",
    "sub036 = image.load_img(\"/home/huskeyadmin/Desktop/merged/sub-036_task-game_run-03_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\")\n",
    "sub037 = image.load_img(\"/home/huskeyadmin/Desktop/merged/sub-037_task-game_run-02_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\")\n",
    "sub039 = image.load_img(\"/home/huskeyadmin/Desktop/merged/sub-039_task-game_run-03_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\")\n",
    "sub040 = image.load_img(\"/home/huskeyadmin/Desktop/merged/sub-040_task-game_run-02_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\")\n",
    "sub041 = image.load_img(\"/home/huskeyadmin/Desktop/merged/sub-041_task-game_run-01_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\")\n",
    "sub042 = image.load_img(\"/home/huskeyadmin/Desktop/merged/sub-042_task-game_run-01_bold_space-MNI152NLin2009cAsym_preproc_merged.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This imports the Power 2011 atlas with 264 cortical and subcortical ROIs\n",
    "\n",
    "power = datasets.fetch_coords_power_2011()\n",
    "print('Power atlas comes with {0}.'.format(power.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes a table with the x,y,z coordinates of each seed ROI\n",
    "\n",
    "coords = np.vstack((power.rois['x'], power.rois['y'], power.rois['z'])).T\n",
    "\n",
    "print('Stacked power coordinates in array of shape {0}.'.format(coords.shape))\n",
    "\n",
    "# The code below exports the ROI x,y,z coordinates of each seed ROI to a text file\n",
    "\n",
    "np.savetxt('power_rois.txt',coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, lets make some masks\n",
    "# Note, these are 5mm spheres so that ROIs do not overlap\n",
    "# They also highpass filter the data since this wasn't done in fmriprep (filter = 250s)\n",
    "\n",
    "masker = input_data.NiftiSpheresMasker(\n",
    "    seeds=coords, smoothing_fwhm=None, radius=5.,\n",
    "    detrend=True, high_pass=.004, t_r=2.0, memory='nilearn_cache', memory_level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a timeseries matrix for each subect for each run\n",
    "# This can be improved with a for loop\n",
    "\n",
    "pooled_subjects = []\n",
    "\n",
    "time_series = masker.fit_transform(sub005)\n",
    "pooled_subjects.append(time_series)\n",
    "time_series = masker.fit_transform(sub006)\n",
    "pooled_subjects.append(time_series)\n",
    "time_series = masker.fit_transform(sub007)\n",
    "pooled_subjects.append(time_series)\n",
    "time_series = masker.fit_transform(sub008)\n",
    "pooled_subjects.append(time_series)\n",
    "time_series = masker.fit_transform(sub009)\n",
    "pooled_subjects.append(time_series)\n",
    "time_series = masker.fit_transform(sub011)\n",
    "pooled_subjects.append(time_series)\n",
    "time_series = masker.fit_transform(sub012)\n",
    "pooled_subjects.append(time_series)\n",
    "time_series = masker.fit_transform(sub014)\n",
    "pooled_subjects.append(time_series)\n",
    "time_series = masker.fit_transform(sub015)\n",
    "pooled_subjects.append(time_series)\n",
    "time_series = masker.fit_transform(sub016)\n",
    "pooled_subjects.append(time_series)\n",
    "time_series = masker.fit_transform(sub017)\n",
    "pooled_subjects.append(time_series)\n",
    "time_series = masker.fit_transform(sub020)\n",
    "pooled_subjects.append(time_series)\n",
    "time_series = masker.fit_transform(sub021)\n",
    "pooled_subjects.append(time_series)\n",
    "time_series = masker.fit_transform(sub023)\n",
    "pooled_subjects.append(time_series)\n",
    "time_series = masker.fit_transform(sub024)\n",
    "pooled_subjects.append(time_series)\n",
    "time_series = masker.fit_transform(sub025)\n",
    "pooled_subjects.append(time_series)\n",
    "time_series = masker.fit_transform(sub026)\n",
    "pooled_subjects.append(time_series)\n",
    "time_series = masker.fit_transform(sub028)\n",
    "pooled_subjects.append(time_series)\n",
    "time_series = masker.fit_transform(sub029)\n",
    "pooled_subjects.append(time_series)\n",
    "time_series = masker.fit_transform(sub030)\n",
    "pooled_subjects.append(time_series)\n",
    "time_series = masker.fit_transform(sub031)\n",
    "pooled_subjects.append(time_series)\n",
    "time_series = masker.fit_transform(sub032)\n",
    "pooled_subjects.append(time_series)\n",
    "time_series = masker.fit_transform(sub033)\n",
    "pooled_subjects.append(time_series)\n",
    "time_series = masker.fit_transform(sub034)\n",
    "pooled_subjects.append(time_series)\n",
    "time_series = masker.fit_transform(sub036)\n",
    "pooled_subjects.append(time_series)\n",
    "time_series = masker.fit_transform(sub037)\n",
    "pooled_subjects.append(time_series)\n",
    "time_series = masker.fit_transform(sub039)\n",
    "pooled_subjects.append(time_series)\n",
    "time_series = masker.fit_transform(sub040)\n",
    "pooled_subjects.append(time_series)\n",
    "time_series = masker.fit_transform(sub041)\n",
    "pooled_subjects.append(time_series)\n",
    "time_series = masker.fit_transform(sub042)\n",
    "pooled_subjects.append(time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If files are being imported correctly, there should 120 volumes reported here\n",
    "\n",
    "print ('timeseries has {0} samples. This is how many volumes there are in the functional run'.format(time_series.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, lets estimate some connectivities using correlation\n",
    "\n",
    "from nilearn.connectome import ConnectivityMeasure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_measure = ConnectivityMeasure(kind='correlation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute individual correlation matricies for each subject\n",
    "\n",
    "correlation_matrices = correlation_measure.fit_transform(pooled_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape should be (n, 264, 264) where n = the number of subjects/runs in your study\n",
    "\n",
    "print('Correlations of subject runs are stacked in an array of shape {0}'\n",
    "      .format(correlation_matrices.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates a mean (group-level) correlation matrix\n",
    "# This tells you the shape of your mean correlation matrix\n",
    "# Shape should just be (264, 264) because you are taking the average correlation of all subjects here\n",
    "\n",
    "mean_correlation_matrix = correlation_measure.mean_\n",
    "print('Mean correlation has shape {0}.'.format(mean_correlation_matrix.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the diagonal to zero (This facilitates the Fishers Z Transform in the next step)\n",
    "\n",
    "np.fill_diagonal(mean_correlation_matrix, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fishers Z Transform the average (group-level) matrix\n",
    "\n",
    "fisherz_mean_correlation_matrix = np.arctanh(mean_correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This saves the Fisher Z transformed correlation matrix as a txt output in the current working directory\n",
    "\n",
    "np.savetxt('flow_cond_corel_matrix.txt',fisherz_mean_correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, lets estimate some connectivities using covariance\n",
    "\n",
    "covariance_measure = ConnectivityMeasure(kind='covariance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariance_matricies = covariance_measure.fit_transform(pooled_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape should be (n, 264, 264) where n = the number of subjects/runs in your study\n",
    "\n",
    "print('Covariances of subject runs are stacked in an array of shape {0}'\n",
    "      .format(covariance_matricies.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tells you the shape of your mean covariance matrix\n",
    "# Shape should just be (264, 264) because you are taking the average correlation of all subjects here\n",
    "\n",
    "mean_covariance_matrix = covariance_measure.mean_\n",
    "print('Mean covariance has shape {0}.'.format(mean_covariance_matrix.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This saves the covariance matrix as a txt output in the current working directory\n",
    "\n",
    "np.savetxt('flow_cond_covar_matrix.txt',mean_covariance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the diagonal to zero for each subject's individual correlation matrix\n",
    "\n",
    "for j in range(len(correlation_matrices)):\n",
    "    np.fill_diagonal(correlation_matrices[j], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fishers Z transforms each subject's correlation matrix\n",
    "\n",
    "fisherz_correlation_matrices = np.arctanh(correlation_matrices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This saves the correlation matrix for each subject as a txt output in the current working directory\n",
    "\n",
    "for i in range(len(fisherz_correlation_matrices)):\n",
    "    np.savetxt('flow_cond_corel_matrix_%i.txt'%i, fisherz_correlation_matrices[i] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
